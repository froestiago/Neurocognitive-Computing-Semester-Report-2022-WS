{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEIoVM3rfBNU"
      },
      "outputs": [],
      "source": [
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "TO_DROP = ['#timestamp', 'index']\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/data/'\n",
        "\n",
        "# Label\n",
        "# 0: Not reading\n",
        "# 1: Reading English\n",
        "# 2: Reading Japanese horizontal\n",
        "# 3: Reading Japanese vertical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njTFnKQrfFBS",
        "outputId": "4defb53e-c4b4-404b-aa9b-053a8b85eee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IhL8VwefBNW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def read_files_days(day):\n",
        "    # This function read and append \n",
        "    persons = ['p2_', 'p3_', 'p4_', 'p5_', 'p6_' , 'p7_', 'p8_', 'p9_', 'p10_']\n",
        "    \n",
        "    df_final = pd.read_csv(DATASET_PATH + 'p1_' + day + '.csv')\n",
        "    df_final = df_final[df_final.label != 0]\n",
        "    df_final.date_time = df_final.date_time.astype('datetime64[s]')\n",
        "    df_final.set_index('date_time', drop= True, inplace= True)\n",
        "    df_final.drop('#timestamp', axis= 1, inplace= True)\n",
        "    df_final = df_final.rolling('30s').mean()\n",
        "\n",
        "    for person in persons:\n",
        "        df = pd.read_csv(DATASET_PATH + person + day + '.csv')\n",
        "        df = df[df.label != 0]\n",
        "        df.date_time = df.date_time.astype('datetime64[s]')\n",
        "        df.set_index('date_time', drop= True, inplace= True)\n",
        "        df.drop('#timestamp', axis= 1, inplace= True)\n",
        "        df = df.rolling('30s').mean()\n",
        "        df_final = df_final.append(df)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    df_final.iloc[:,0:-1] = scaler.fit_transform(df_final.iloc[:,0:-1].to_numpy())\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "def eval(model, X_test, y_test):\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    cm = cm / cm.astype(np.float).sum(axis= 1)\n",
        "    print('Confusion Matrix:\\n\\t', cm)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('accuracy:\\n\\t', acc)\n",
        "\n",
        "    score_f1 = f1_score(y_test, y_pred, average= None)\n",
        "    print('f1 score:\\n\\t', score_f1)\n"
      ],
      "metadata": {
        "id": "4BgWfCX-mRcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_sV6s4rfBNW",
        "outputId": "a04eb8f8-d6cc-4bd1-b8e7-23378cc8bd19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas dataframe\n",
            "                         left     right     acc_x     acc_y     acc_z  \\\n",
            "date_time                                                               \n",
            "2019-06-06 09:45:04  2.343210  0.490600 -1.673025  2.032946  2.744057   \n",
            "2019-06-06 09:45:04  2.371408  0.504542 -1.668741  2.018716  2.773732   \n",
            "2019-06-06 09:45:04  2.352609  0.493698 -1.658338  2.009594  2.813629   \n",
            "2019-06-06 09:45:04  2.360834  0.492924 -1.642937  2.000157  2.870547   \n",
            "2019-06-06 09:45:04  2.377048  0.488741 -1.632146  1.983826  2.935165   \n",
            "\n",
            "                          roll     pitch       yaw  label  \n",
            "date_time                                                  \n",
            "2019-06-06 09:45:04 -10.904685  3.449941  0.740608    2.0  \n",
            "2019-06-06 09:45:04 -11.262083  3.130638  1.207241    2.0  \n",
            "2019-06-06 09:45:04 -11.249254  2.746713  1.612476    2.0  \n",
            "2019-06-06 09:45:04 -11.168610  2.523391  1.910261    2.0  \n",
            "2019-06-06 09:45:04 -11.082834  2.405362  2.097528    2.0  \n",
            "numpy array (this will be used for training)\n",
            "[[  2.344    0.4905  -1.673    2.033    2.744  -10.91     3.45     0.7407]\n",
            " [  2.371    0.5044  -1.669    2.02     2.773  -11.266    3.13     1.207 ]\n",
            " [  2.354    0.4937  -1.658    2.01     2.814  -11.25     2.746    1.612 ]\n",
            " [  2.361    0.493   -1.643    2.       2.871  -11.17     2.523    1.91  ]\n",
            " [  2.377    0.4888  -1.632    1.983    2.936  -11.086    2.406    2.098 ]]\n"
          ]
        }
      ],
      "source": [
        "df = read_files_days('d1')\n",
        "print('pandas dataframe')\n",
        "print(df.head())\n",
        "\n",
        "# df.drop(df.index, axis= 1, inplace= True)\n",
        "\n",
        "\n",
        "y_train = df.label.to_numpy()\n",
        "y_train = np.array(y_train, dtype=int)\n",
        "X_train = df.drop('label', axis= 1).to_numpy(dtype= np.float16)\n",
        "print('numpy array (this will be used for training)')\n",
        "print(X_train[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90JtWGotfBNX"
      },
      "outputs": [],
      "source": [
        "df = read_files_days('d2')\n",
        "\n",
        "df = shuffle(df)\n",
        "# df.drop('date_time', axis= 1, inplace= True)\n",
        "\n",
        "y_test = df.label.to_numpy()\n",
        "y_test = np.array(y_test, dtype=int)\n",
        "X_test = df.drop('label', axis= 1).to_numpy(dtype= np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6JpAUQtfBNZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "random_forest=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "random_forest.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ_D4LyRfBNZ"
      },
      "outputs": [],
      "source": [
        "eval(random_forest, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gd_boost_default = GradientBoostingClassifier()\n",
        "gd_boost_default.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fQ-yde4BndWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(gd_boost_default, X_test, y_test)"
      ],
      "metadata": {
        "id": "G5aVP8XKPPaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gd_boost_tweaked = GradientBoostingClassifier(learning_rate= 0.2, n_estimators= 50,\n",
        "                                      max_features= 'sqrt', warm_start= True, subsample= 0.8)\n",
        "gd_boost_tweaked.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "IbhPkO164z4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(gd_boost_tweaked, X_test, y_test)"
      ],
      "metadata": {
        "id": "DcZ6hN3_41UF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a1ba579f5b0781e2ab0c36c6a07a3ad31c92b80d44acc8c2bb9841b0a7ee96c0"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}